#k-means++ for Clickhouse SQL
![4clusters](https://github.com/bvt123/clickhouse-k-means/raw/main/4clusters.png?raw=true)

some ideas borrowed from https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.109.5005&rep=rep1&type=pdf

 Делим исходные данные на кластеры, опираясь на поняние "близости" в каком-то многомерном евклидовм пространстве

 - Данных много.
 - Исходые данные могут быть шардированы - лежать в Distributed таблице
 - результатом должен быть  массив PK исходных строк для выявленных кластеров
 
## Зачем clickhouse
 Выгода делать это все не обычным образом (скажем через стандартную библиотеку питона), а внутри КХ на его SQL диалекте заключается в следующем:
- многопоточность по ядрам получается "сама", не нужно ничего специально программировать, КХ будет читать с диска данные в 8 потоков и там-же делать самое сложное вычисление - евклидову дистанцию
- шардинг (если данные уже разложены по серверам) - ускоряет в N раз, так как точки будут обсчитываться  параллельно  и независимо отдельными серверами.
- UDF на питоне тоже решают задачу через 100+ библиотек с доступными реализациям k-means. Только нужно учитывать, что копий питона запускается много, и КХ будет их кормить данными в параллель. Важно чтобы скрипт это учитывал, и работал соответственно.  Получаеся довольно непростое программирование шаред мемори (для хранения центроидов) и прочий непростой interprocess communications.

